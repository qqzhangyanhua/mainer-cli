# OpsAI ä¼˜åŒ–å®æ–½è¯¦ç»†è®¡åˆ’

> åŸºäºäº§å“ä¼˜åŒ–å»ºè®®æŠ¥å‘Šçš„å¯æ‰§è¡Œå®æ–½è®¡åˆ’
> é¢„è®¡æ€»å·¥æœŸï¼š6-8 å‘¨
> å›¢é˜Ÿè§„æ¨¡ï¼š1-2 äºº

---

## ğŸ“… é¡¹ç›®æ—¶é—´çº¿æ€»è§ˆ

```
Week 1-2:  P0 é˜¶æ®µ - æ ¸å¿ƒåŠŸèƒ½ç²¾ç®€
Week 3-4:  P1 é˜¶æ®µ - ä½“éªŒä¼˜åŒ–ï¼ˆç¬¬ä¸€éƒ¨åˆ†ï¼‰
Week 5-6:  P1 é˜¶æ®µ - ä½“éªŒä¼˜åŒ–ï¼ˆç¬¬äºŒéƒ¨åˆ†ï¼‰
Week 7-8:  P2 é˜¶æ®µ - åŠŸèƒ½å¢å¼ºï¼ˆå¯é€‰ï¼‰
```

---

## ğŸ¯ P0 é˜¶æ®µï¼šæ ¸å¿ƒåŠŸèƒ½ç²¾ç®€ï¼ˆç¬¬ 1-2 å‘¨ï¼‰

**ç›®æ ‡**ï¼šåˆ å‡ 30% çš„ä»£ç ï¼Œè®©æ ¸å¿ƒåœºæ™¯ä½“éªŒæå‡ 300%

### Task 1.1ï¼šç§»é™¤ Tavily æœç´¢ä¾èµ– â±ï¸ 4 å°æ—¶

**ä¸ºä»€ä¹ˆåš**ï¼š
- å¤–éƒ¨æœç´¢åœ¨è¿ç»´åœºæ™¯ä»·å€¼æœ‰é™
- å‡å°‘ API é…ç½®æˆæœ¬
- é™ä½ LLM ç”Ÿæˆä¸ç¡®å®šæ€§

**å…·ä½“æ­¥éª¤**ï¼š

#### 1.1.1 ä»£ç ç§»é™¤
```bash
# 1. åˆ é™¤ Worker æ–‡ä»¶
rm src/workers/tavily.py

# 2. åˆ é™¤æµ‹è¯•æ–‡ä»¶
rm tests/test_tavily_worker.py

# 3. æ›´æ–° pyproject.toml
# åˆ é™¤ä¾èµ–ï¼štavily-python>=0.5.0
```

#### 1.1.2 æ¸…ç†å¼•ç”¨
```python
# æ–‡ä»¶ï¼šsrc/orchestrator/prompt.py
# åˆ é™¤ WORKER_CAPABILITIES ä¸­çš„ tavily é…ç½®
WORKER_CAPABILITIES: dict[str, list[str]] = {
    # ...
    # "tavily": ["search", "extract"],  # â† åˆ é™¤è¿™è¡Œ
}
```

```python
# æ–‡ä»¶ï¼šsrc/orchestrator/engine.py
# åˆ é™¤ TavilyWorker çš„å¯¼å…¥å’Œæ³¨å†Œ
# from src.workers.tavily import TavilyWorker  # â† åˆ é™¤
# self._workers["tavily"] = TavilyWorker(...)  # â† åˆ é™¤
```

#### 1.1.3 éªŒè¯
```bash
# è¿è¡Œæµ‹è¯•ç¡®ä¿æ²¡æœ‰æ®‹ç•™å¼•ç”¨
uv run pytest -v
uv run mypy src/
```

**äº§å‡º**ï¼š
- âœ… åˆ é™¤ 2 ä¸ªæ–‡ä»¶ï¼ˆ~400 è¡Œä»£ç ï¼‰
- âœ… å‡å°‘ 1 ä¸ªå¤–éƒ¨ä¾èµ–
- âœ… é€šè¿‡æ‰€æœ‰æµ‹è¯•

---

### Task 1.2ï¼šåˆå¹¶ cache.py åˆ° analyze.py â±ï¸ 6 å°æ—¶

**ä¸ºä»€ä¹ˆåš**ï¼š
- Cache æ˜¯ Analyze çš„å†…éƒ¨å®ç°ç»†èŠ‚ï¼Œä¸åº”ç‹¬ç«‹æš´éœ²
- ç®€åŒ– Workers æ•°é‡ï¼Œé™ä½ç†è§£æˆæœ¬

**å…·ä½“æ­¥éª¤**ï¼š

#### 1.2.1 é‡æ„ AnalyzeWorker
```python
# æ–‡ä»¶ï¼šsrc/workers/analyze.py

from typing import Optional
import json
from pathlib import Path

class AnalyzeWorker(BaseWorker):
    """æ™ºèƒ½åˆ†æ Workerï¼ˆå†…ç½®ç¼“å­˜ï¼‰"""
    
    # å†…éƒ¨ç¼“å­˜ç®¡ç†
    _CACHE_FILE = Path.home() / ".opsai" / "analyze_cache.json"
    
    def __init__(self, llm_client: LLMClient):
        self._llm_client = llm_client
        self._shell_worker = ShellWorker()
        self._cache: dict[str, list[str]] = self._load_cache()
    
    def _load_cache(self) -> dict[str, list[str]]:
        """åŠ è½½ç¼“å­˜ï¼ˆå†…éƒ¨æ–¹æ³•ï¼‰"""
        if self._CACHE_FILE.exists():
            try:
                with open(self._CACHE_FILE, "r") as f:
                    return json.load(f)
            except Exception:
                return {}
        return {}
    
    def _save_cache(self) -> None:
        """ä¿å­˜ç¼“å­˜ï¼ˆå†…éƒ¨æ–¹æ³•ï¼‰"""
        self._CACHE_FILE.parent.mkdir(parents=True, exist_ok=True)
        with open(self._CACHE_FILE, "w") as f:
            json.dump(self._cache, f, indent=2)
    
    def _get_cached_commands(self, target_type: str) -> Optional[list[str]]:
        """ä»ç¼“å­˜è·å–å‘½ä»¤"""
        return self._cache.get(target_type)
    
    def _cache_commands(self, target_type: str, commands: list[str]) -> None:
        """ç¼“å­˜å‘½ä»¤"""
        self._cache[target_type] = commands
        self._save_cache()
    
    async def _get_analyze_commands(self, target_type: str, target_name: str) -> list[str]:
        """è·å–åˆ†æå‘½ä»¤åˆ—è¡¨ï¼ˆä¼˜å…ˆçº§ï¼šç¼“å­˜ > é¢„ç½® > LLMï¼‰"""
        # 1. å°è¯•ä»ç¼“å­˜è·å–
        cached = self._get_cached_commands(target_type)
        if cached:
            return cached
        
        # 2. ä½¿ç”¨é¢„ç½®é»˜è®¤å‘½ä»¤
        if target_type in DEFAULT_ANALYZE_COMMANDS:
            return DEFAULT_ANALYZE_COMMANDS[target_type]
        
        # 3. LLM ç”Ÿæˆ
        commands = await self._generate_commands_via_llm(target_type, target_name)
        if commands:
            self._cache_commands(target_type, commands)
        
        return commands
```

#### 1.2.2 åˆ é™¤æ—§æ–‡ä»¶
```bash
# åˆ é™¤ç‹¬ç«‹çš„ Cache Worker
rm src/workers/cache.py
```

#### 1.2.3 æ›´æ–°æµ‹è¯•
```python
# æ–‡ä»¶ï¼štests/test_analyze_worker.py

def test_analyze_with_internal_cache():
    """æµ‹è¯•å†…ç½®ç¼“å­˜åŠŸèƒ½"""
    worker = AnalyzeWorker(llm_client=mock_llm)
    
    # ç¬¬ä¸€æ¬¡è°ƒç”¨ï¼ˆç”Ÿæˆå¹¶ç¼“å­˜ï¼‰
    result1 = await worker.execute("explain", {"target": "nginx", "type": "docker"})
    
    # ç¬¬äºŒæ¬¡è°ƒç”¨ï¼ˆä»ç¼“å­˜è¯»å–ï¼‰
    result2 = await worker.execute("explain", {"target": "nginx", "type": "docker"})
    
    # éªŒè¯ç¼“å­˜ç”Ÿæ•ˆï¼ˆLLM åªè°ƒç”¨ä¸€æ¬¡ï¼‰
    assert mock_llm.call_count == 1
```

**äº§å‡º**ï¼š
- âœ… åˆ é™¤ 1 ä¸ªç‹¬ç«‹ Worker æ–‡ä»¶ï¼ˆ~150 è¡Œä»£ç ï¼‰
- âœ… AnalyzeWorker ä»£ç å¢åŠ  ~100 è¡Œï¼ˆå‡€å‡å°‘ 50 è¡Œï¼‰
- âœ… æ›´æ–°ç›¸å…³æµ‹è¯•

---

### Task 1.3ï¼šç®€åŒ– Deploy ä¸ºä¸€é”®éƒ¨ç½² â±ï¸ 8 å°æ—¶

**ä¸ºä»€ä¹ˆåš**ï¼š
- å½“å‰æµç¨‹éœ€è¦ç”¨æˆ·ç†è§£ 4 ä¸ªæ­¥éª¤ï¼ˆanalyze â†’ clone â†’ setup â†’ startï¼‰
- æ–°æ‰‹åªéœ€è¦ï¼š"ç»™æˆ‘ä¸€ä¸ª URLï¼Œç›´æ¥å¯åŠ¨"

**å…·ä½“æ­¥éª¤**ï¼š

#### 1.3.1 æ–°å¢é«˜å±‚æ¥å£
```python
# æ–‡ä»¶ï¼šsrc/workers/deploy.py

class DeployWorker(BaseWorker):
    """GitHub é¡¹ç›®éƒ¨ç½² Worker"""
    
    def get_capabilities(self) -> list[str]:
        # ç®€åŒ–å¯¹å¤–èƒ½åŠ›ï¼šåªæš´éœ²ä¸€é”®éƒ¨ç½²
        return ["deploy"]  # ä¸å†æš´éœ² analyze_repo, clone_repo ç­‰
    
    async def execute(self, action: str, args: dict[str, ArgValue]) -> WorkerResult:
        if action == "deploy":
            return await self._one_click_deploy(args)
        # ä¿ç•™å†…éƒ¨æ–¹æ³•ï¼ˆanalyze, clone, setup, startï¼‰
        # ä½†ä¸å¯¹å¤–æš´éœ²
    
    async def _one_click_deploy(self, args: dict[str, ArgValue]) -> WorkerResult:
        """ä¸€é”®éƒ¨ç½² GitHub é¡¹ç›®
        
        Args:
            args: {
                "repo_url": "https://github.com/owner/repo",
                "target_dir": "~/projects"  # å¯é€‰
            }
        
        Returns:
            WorkerResult: éƒ¨ç½²ç»“æœï¼ˆåŒ…å«æ‰€æœ‰æ­¥éª¤çš„æ‘˜è¦ï¼‰
        """
        repo_url = args.get("repo_url")
        if not isinstance(repo_url, str):
            return WorkerResult(
                success=False,
                message="repo_url parameter is required",
            )
        
        target_dir = args.get("target_dir", "~/projects")
        dry_run = args.get("dry_run", False)
        
        steps_log = []
        
        # Step 1: åˆ†æé¡¹ç›®
        steps_log.append("ğŸ“‹ Step 1/4: åˆ†æé¡¹ç›®ç»“æ„...")
        analyze_result = await self._analyze_repo({"repo_url": repo_url})
        if not analyze_result.success:
            return WorkerResult(
                success=False,
                message=f"âŒ åˆ†æå¤±è´¥ï¼š{analyze_result.message}",
            )
        
        project_type = analyze_result.data.get("project_type", "unknown") if analyze_result.data else "unknown"
        steps_log.append(f"  âœ“ æ£€æµ‹åˆ°é¡¹ç›®ç±»å‹ï¼š{project_type}")
        
        # Step 2: å…‹éš†ä»“åº“
        steps_log.append("ğŸ“¦ Step 2/4: å…‹éš†ä»“åº“...")
        clone_result = await self._clone_repo({
            "repo_url": repo_url,
            "target_dir": target_dir,
            "dry_run": dry_run,
        })
        if not clone_result.success:
            return WorkerResult(
                success=False,
                message="\n".join(steps_log) + f"\nâŒ å…‹éš†å¤±è´¥ï¼š{clone_result.message}",
            )
        
        project_dir = clone_result.data.get("path") if clone_result.data else ""
        already_exists = clone_result.data.get("already_exists", False) if clone_result.data else False
        if already_exists:
            steps_log.append(f"  âš ï¸ é¡¹ç›®å·²å­˜åœ¨ï¼š{project_dir}")
        else:
            steps_log.append(f"  âœ“ å…‹éš†å®Œæˆï¼š{project_dir}")
        
        # Step 3: é…ç½®ç¯å¢ƒ
        steps_log.append("âš™ï¸  Step 3/4: é…ç½®ç¯å¢ƒ...")
        setup_result = await self._setup_env({
            "project_dir": project_dir,
            "project_type": project_type,
            "dry_run": dry_run,
        })
        if not setup_result.success:
            return WorkerResult(
                success=False,
                message="\n".join(steps_log) + f"\nâŒ ç¯å¢ƒé…ç½®å¤±è´¥ï¼š{setup_result.message}",
            )
        steps_log.append(f"  âœ“ ç¯å¢ƒé…ç½®å®Œæˆ")
        
        # Step 4: å¯åŠ¨æœåŠ¡
        steps_log.append("ğŸš€ Step 4/4: å¯åŠ¨æœåŠ¡...")
        start_result = await self._start_service({
            "project_dir": project_dir,
            "project_type": project_type,
            "dry_run": dry_run,
        })
        if not start_result.success:
            # å¯åŠ¨å¤±è´¥æ—¶ï¼Œæä¾›è¯¦ç»†çš„é”™è¯¯æç¤º
            error_msg = start_result.message
            suggestions = self._generate_error_suggestions(project_type, error_msg)
            return WorkerResult(
                success=False,
                message="\n".join(steps_log) + 
                        f"\nâŒ å¯åŠ¨å¤±è´¥ï¼š{error_msg}\n\n" +
                        f"ğŸ’¡ å¯èƒ½çš„è§£å†³æ–¹æ³•ï¼š\n{suggestions}",
            )
        
        steps_log.append(f"  âœ“ æœåŠ¡å¯åŠ¨æˆåŠŸï¼")
        
        # æˆåŠŸæ‘˜è¦
        summary = "\n".join(steps_log)
        summary += f"\n\nâœ… éƒ¨ç½²å®Œæˆï¼"
        summary += f"\nğŸ“‚ é¡¹ç›®è·¯å¾„ï¼š{project_dir}"
        summary += f"\nğŸ¯ é¡¹ç›®ç±»å‹ï¼š{project_type}"
        
        if dry_run:
            summary = "[DRY-RUN æ¨¡å¼]\n\n" + summary
        
        return WorkerResult(
            success=True,
            data={
                "project_dir": str(project_dir),
                "project_type": str(project_type),
                "repo_url": repo_url,
            },
            message=summary,
            task_completed=True,
            simulated=dry_run,
        )
    
    def _generate_error_suggestions(self, project_type: str, error_msg: str) -> str:
        """æ ¹æ®é”™è¯¯ä¿¡æ¯ç”Ÿæˆå»ºè®®"""
        suggestions = []
        
        if "permission denied" in error_msg.lower():
            suggestions.append("1. æ£€æŸ¥æ–‡ä»¶æƒé™ï¼šchmod +x start.sh")
            suggestions.append("2. ä½¿ç”¨ sudoï¼ˆå¦‚æœéœ€è¦ï¼‰")
        
        if "port" in error_msg.lower() or "address already in use" in error_msg.lower():
            suggestions.append("1. æ£€æŸ¥ç«¯å£å ç”¨ï¼šlsof -i :ç«¯å£å·")
            suggestions.append("2. ä¿®æ”¹é…ç½®æ–‡ä»¶ä¸­çš„ç«¯å£")
        
        if ".env" in error_msg.lower() or "environment" in error_msg.lower():
            suggestions.append("1. æ£€æŸ¥ .env æ–‡ä»¶æ˜¯å¦å­˜åœ¨")
            suggestions.append("2. ä» .env.example å¤åˆ¶å¹¶å¡«å†™å¿…è¦é…ç½®")
        
        if project_type == "docker" and "docker" in error_msg.lower():
            suggestions.append("1. ç¡®ä¿ Docker æ­£åœ¨è¿è¡Œï¼šdocker ps")
            suggestions.append("2. æ£€æŸ¥ docker-compose.yml é…ç½®")
        
        if not suggestions:
            suggestions.append("1. æŸ¥çœ‹é¡¹ç›® README äº†è§£éƒ¨ç½²è¦æ±‚")
            suggestions.append("2. æ£€æŸ¥é¡¹ç›®ç›®å½•ä¸­çš„é”™è¯¯æ—¥å¿—")
        
        return "\n".join(suggestions)
```

#### 1.3.2 æ›´æ–° CLI å‘½ä»¤
```python
# æ–‡ä»¶ï¼šsrc/cli.py

@app.command()
def deploy(
    repo_url: str = typer.Argument(..., help="GitHub ä»“åº“ URL"),
    target_dir: str = typer.Option("~/projects", help="éƒ¨ç½²ç›®æ ‡ç›®å½•"),
    dry_run: bool = typer.Option(False, "--dry-run", help="æ¨¡æ‹Ÿæ‰§è¡Œï¼Œä¸å®é™…éƒ¨ç½²"),
):
    """ä¸€é”®éƒ¨ç½² GitHub é¡¹ç›®
    
    ç¤ºä¾‹ï¼š
        opsai deploy https://github.com/user/my-app
        opsai deploy https://github.com/user/my-app --target-dir ~/myprojects
        opsai deploy https://github.com/user/my-app --dry-run
    """
    console = Console()
    
    with console.status("[bold green]æ­£åœ¨éƒ¨ç½²é¡¹ç›®..."):
        # è°ƒç”¨ DeployWorker çš„ä¸€é”®éƒ¨ç½²
        result = asyncio.run(_deploy_project(repo_url, target_dir, dry_run))
    
    if result.success:
        console.print(Panel(result.message, title="âœ… éƒ¨ç½²æˆåŠŸ", border_style="green"))
    else:
        console.print(Panel(result.message, title="âŒ éƒ¨ç½²å¤±è´¥", border_style="red"))
        raise typer.Exit(code=1)

async def _deploy_project(repo_url: str, target_dir: str, dry_run: bool) -> WorkerResult:
    """æ‰§è¡Œéƒ¨ç½²"""
    from src.workers.deploy import DeployWorker
    from src.workers.http import HttpWorker
    from src.workers.shell import ShellWorker
    
    http_worker = HttpWorker()
    shell_worker = ShellWorker()
    deploy_worker = DeployWorker(http_worker, shell_worker)
    
    return await deploy_worker.execute("deploy", {
        "repo_url": repo_url,
        "target_dir": target_dir,
        "dry_run": dry_run,
    })
```

#### 1.3.3 æ›´æ–° Prompt
```python
# æ–‡ä»¶ï¼šsrc/orchestrator/prompt.py

WORKER_CAPABILITIES: dict[str, list[str]] = {
    # ...
    "deploy": ["deploy"],  # ç®€åŒ–ï¼šåªæ˜¾ç¤ºä¸€ä¸ªèƒ½åŠ›
}

# åœ¨ build_system_prompt ä¸­æ›´æ–°æè¿°
"""
- deploy.deploy: ä¸€é”®éƒ¨ç½² GitHub é¡¹ç›®ï¼ˆè‡ªåŠ¨å®Œæˆåˆ†æâ†’å…‹éš†â†’é…ç½®â†’å¯åŠ¨ï¼‰
  - args: {"repo_url": "https://github.com/owner/repo", "target_dir": "~/projects"}
  - ç¤ºä¾‹: {"worker": "deploy", "action": "deploy", "args": {"repo_url": "https://github.com/user/app"}, "risk_level": "medium"}
"""
```

#### 1.3.4 æµ‹è¯•
```python
# æ–‡ä»¶ï¼štests/test_deploy_integration.py

async def test_one_click_deploy_success():
    """æµ‹è¯•ä¸€é”®éƒ¨ç½²æˆåŠŸæµç¨‹"""
    deploy_worker = DeployWorker(mock_http, mock_shell)
    
    result = await deploy_worker.execute("deploy", {
        "repo_url": "https://github.com/test/repo",
    })
    
    assert result.success
    assert "âœ… éƒ¨ç½²å®Œæˆ" in result.message
    assert "é¡¹ç›®è·¯å¾„" in result.message
    assert result.task_completed

async def test_one_click_deploy_with_error_suggestions():
    """æµ‹è¯•éƒ¨ç½²å¤±è´¥æ—¶çš„å»ºè®®"""
    # Mock ç«¯å£å ç”¨é”™è¯¯
    mock_shell.set_error("address already in use: 8080")
    
    result = await deploy_worker.execute("deploy", {
        "repo_url": "https://github.com/test/repo",
    })
    
    assert not result.success
    assert "å¯èƒ½çš„è§£å†³æ–¹æ³•" in result.message
    assert "æ£€æŸ¥ç«¯å£å ç”¨" in result.message
```

**äº§å‡º**ï¼š
- âœ… æ–°å¢ `_one_click_deploy` æ–¹æ³•ï¼ˆ~150 è¡Œï¼‰
- âœ… æ–°å¢ CLI å‘½ä»¤ `opsai deploy`
- âœ… æ™ºèƒ½é”™è¯¯æç¤ºæœºåˆ¶
- âœ… æ›´æ–°æµ‹è¯•è¦†ç›–

---

### Task 1.4ï¼šé‡å†™ READMEï¼ˆ5 åˆ†é’Ÿå¿«é€Ÿä¸Šæ‰‹ï¼‰â±ï¸ 4 å°æ—¶

**ä¸ºä»€ä¹ˆåš**ï¼š
- å½“å‰ README å¤ªé•¿ï¼Œæ–°æ‰‹ä¸çŸ¥é“ä»å“ªå¼€å§‹
- éœ€è¦"çœ‹å®Œå‰ 5 è¡Œå°±èƒ½ä¸Šæ‰‹"çš„ä½“éªŒ

**å…·ä½“æ­¥éª¤**ï¼š

#### 1.4.1 æ–°çš„ README ç»“æ„
```markdown
# OpsAI - 5 åˆ†é’Ÿå­¦ä¼šè¿ç»´

> ğŸš€ ç”¨è‡ªç„¶è¯­è¨€æ“ä½œæœåŠ¡å™¨ï¼Œæ— éœ€è®°å‘½ä»¤

**æ ¸å¿ƒèƒ½åŠ›**ï¼šæŸ¥æ—¥å¿— Â· æŸ¥çŠ¶æ€ Â· é‡å¯æœåŠ¡ Â· æ£€æŸ¥èµ„æº

## âš¡ å¿«é€Ÿå¼€å§‹ï¼ˆ3 æ­¥ä¸Šæ‰‹ï¼‰

### 1ï¸âƒ£ å®‰è£…
```bash
pip install opsai
```

### 2ï¸âƒ£ å¯åŠ¨
```bash
opsai-tui
```

### 3ï¸âƒ£ è¯•è¯•è¿™ 3 ä¸ªå‘½ä»¤
```
> æŸ¥çœ‹æ‰€æœ‰å®¹å™¨
> æŸ¥çœ‹ç£ç›˜ç©ºé—´
> æŸ¥çœ‹æœ€è¿‘çš„æ—¥å¿—
```

**[ğŸ“º è§‚çœ‹ 30 ç§’æ¼”ç¤ºè§†é¢‘](#demo)**

---

## ğŸ¯ å¸¸è§åœºæ™¯ï¼ˆç‚¹å‡»æŸ¥çœ‹ç¤ºä¾‹ï¼‰

<details>
<summary>ğŸ”´ <b>æœåŠ¡å‡ºé—®é¢˜äº†</b></summary>

```bash
# åœºæ™¯ 1ï¼šç½‘ç«™æ‰“ä¸å¼€
opsai-tui
> "æˆ‘çš„ç½‘ç«™æ‰“ä¸å¼€"
# â†’ è‡ªåŠ¨æ£€æµ‹ nginx å®¹å™¨çŠ¶æ€ + ç«¯å£ç›‘å¬ + æŸ¥çœ‹æ—¥å¿—

# åœºæ™¯ 2ï¼šæŸ¥çœ‹ç‰¹å®šæœåŠ¡æ—¥å¿—
> "æŸ¥çœ‹ api-server çš„æ—¥å¿—"
# â†’ è‡ªåŠ¨è¯†åˆ«å®¹å™¨/systemd æœåŠ¡ï¼Œæ˜¾ç¤ºæœ€è¿‘ 100 è¡Œæ—¥å¿—

# åœºæ™¯ 3ï¼šé‡å¯æœåŠ¡
> "é‡å¯ nginx"
# â†’ å®‰å…¨ç¡®è®¤åæ‰§è¡Œé‡å¯ï¼Œå¹¶éªŒè¯å¯åŠ¨æˆåŠŸ
```
</details>

<details>
<summary>ğŸ’¾ <b>ç£ç›˜ç©ºé—´ä¸è¶³</b></summary>

```bash
opsai-tui
> "ç£ç›˜å¿«æ»¡äº†ï¼Œå¸®æˆ‘æ¸…ç†"
# â†’ è‡ªåŠ¨æŸ¥æ‰¾å¤§æ–‡ä»¶ + å»ºè®®å¯æ¸…ç†çš„å†…å®¹ + å®‰å…¨åˆ é™¤
```
</details>

<details>
<summary>ğŸš€ <b>éƒ¨ç½² GitHub é¡¹ç›®</b></summary>

```bash
# ä¸€é”®éƒ¨ç½²ï¼ˆè‡ªåŠ¨æ£€æµ‹é¡¹ç›®ç±»å‹ï¼‰
opsai deploy https://github.com/user/my-app

# æˆ–é€šè¿‡ TUI
opsai-tui
> "å¸®æˆ‘éƒ¨ç½² https://github.com/user/my-app"
```
</details>

<details>
<summary>ğŸŒ <b>æœåŠ¡å“åº”æ…¢</b></summary>

```bash
opsai-tui
> "æœåŠ¡å¾ˆæ…¢ï¼Œå¸®æˆ‘çœ‹çœ‹"
# â†’ æ£€æŸ¥ CPU/å†…å­˜å ç”¨ + åˆ†ææ…¢æŸ¥è¯¢æ—¥å¿— + å»ºè®®ä¼˜åŒ–æ–¹æ¡ˆ
```
</details>

---

## ğŸ”’ å®‰å…¨ä¿éšœ

- âœ… **å±é™©æ“ä½œæ‹¦æˆª**ï¼šè‡ªåŠ¨è¯†åˆ« `rm -rf`, `kill -9` ç­‰é«˜å±å‘½ä»¤
- âœ… **äºŒæ¬¡ç¡®è®¤**ï¼šç ´åæ€§æ“ä½œéœ€è¦æ‰‹åŠ¨ç¡®è®¤
- âœ… **Dry-run æ¨¡å¼**ï¼šé¢„è§ˆæ“ä½œï¼Œä¸å®é™…æ‰§è¡Œ
- âœ… **å®¡è®¡æ—¥å¿—**ï¼šæ‰€æœ‰æ“ä½œè‡ªåŠ¨è®°å½•åˆ° `~/.opsai/audit.log`

---

## ğŸ“– è¿›é˜¶ä½¿ç”¨

### é…ç½® LLM
```bash
# ä½¿ç”¨æœ¬åœ° Ollamaï¼ˆæ¨èï¼‰
opsai config set-llm --model qwen2.5:7b --base-url http://localhost:11434/v1

# ä½¿ç”¨ OpenAI
opsai config set-llm --model gpt-4o --api-key sk-xxx
```

### CLI æ¨¡å¼ï¼ˆå¿«é€Ÿæ‰§è¡Œå•æ¡å‘½ä»¤ï¼‰
```bash
opsai query "æŸ¥çœ‹ç£ç›˜ä½¿ç”¨æƒ…å†µ"
opsai query "åˆ—å‡ºæ‰€æœ‰å®¹å™¨" --dry-run
```

### æ›´å¤šåŠŸèƒ½
- [æ™ºèƒ½å¯¹è±¡åˆ†æ](docs/features/analyze.md)ï¼ˆ"è¿™ä¸ªå®¹å™¨æ˜¯å¹²å˜›çš„"ï¼‰
- [è‡ªå®šä¹‰åœºæ™¯](docs/features/scenarios.md)ï¼ˆä¿å­˜å¸¸ç”¨æ“ä½œï¼‰
- [æ‰©å±•å¼€å‘](docs/development/extend-workers.md)ï¼ˆæ·»åŠ è‡ªå®šä¹‰ Workerï¼‰

---

## â“ å¸¸è§é—®é¢˜

**Q: æ”¯æŒå“ªäº›è¿ç»´å·¥å…·ï¼Ÿ**  
A: Dockerã€Systemdã€é€šç”¨ Shell å‘½ä»¤ã€‚æœªæ¥æ”¯æŒ Kubernetesã€‚

**Q: éœ€è¦ root æƒé™å—ï¼Ÿ**  
A: ä¸éœ€è¦ã€‚ç»§æ‰¿å½“å‰ç”¨æˆ·æƒé™ï¼Œä¸æ¶‰åŠææƒã€‚

**Q: æ•°æ®å®‰å…¨å—ï¼Ÿ**  
A: æ‰€æœ‰æ•°æ®åœ¨æœ¬åœ°å¤„ç†ï¼Œä¸ä¸Šä¼ åˆ°äº‘ç«¯ï¼ˆLLM API é™¤å¤–ï¼‰ã€‚

**Q: å¦‚ä½•å¸è½½ï¼Ÿ**  
A: `pip uninstall opsai` + åˆ é™¤ `~/.opsai/` ç›®å½•ã€‚

---

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ PRï¼è¯¦è§ [è´¡çŒ®æŒ‡å—](CONTRIBUTING.md)ã€‚

## ğŸ“„ å¼€æºåè®®

MIT License
```

#### 1.4.2 å½•åˆ¶æ¼”ç¤ºè§†é¢‘
```bash
# ä½¿ç”¨ asciinema å½•åˆ¶ç»ˆç«¯æ“ä½œ
asciinema rec demo.cast

# æ“ä½œæµç¨‹ï¼š
1. opsai-tui
2. è¾“å…¥"æŸ¥çœ‹æ‰€æœ‰å®¹å™¨"
3. è¾“å…¥"è¿™ä¸ªæ˜¯å¹²å˜›çš„"ï¼ˆæŒ‡ä»£è§£ææ¼”ç¤ºï¼‰
4. è¾“å…¥"æŸ¥çœ‹æ—¥å¿—"
5. é€€å‡º

# è½¬æ¢ä¸º GIF
agg demo.cast demo.gif
```

#### 1.4.3 æ–°å¢å¿«é€Ÿä¸Šæ‰‹æ–‡æ¡£
```bash
# åˆ›å»º docs/quickstart/
mkdir -p docs/quickstart
touch docs/quickstart/5min-guide.md
touch docs/quickstart/scenarios.md
touch docs/quickstart/faq.md
```

**äº§å‡º**ï¼š
- âœ… ç²¾ç®€ READMEï¼ˆä» 200 è¡Œ â†’ 100 è¡Œï¼‰
- âœ… 30 ç§’æ¼”ç¤ºè§†é¢‘/GIF
- âœ… åœºæ™¯åŒ–ç¤ºä¾‹ï¼ˆæŠ˜å å¼å±•ç¤ºï¼‰

---

### Task 1.5ï¼šæµ‹è¯•ä¸å‘å¸ƒ â±ï¸ 4 å°æ—¶

#### 1.5.1 å›å½’æµ‹è¯•
```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
uv run pytest -v --cov=src --cov-report=html

# æ£€æŸ¥è¦†ç›–ç‡ï¼ˆç›®æ ‡ > 80%ï¼‰
open htmlcov/index.html

# ç±»å‹æ£€æŸ¥
uv run mypy src/

# ä»£ç æ ¼å¼
uv run ruff check src/ tests/
uv run ruff format src/ tests/
```

#### 1.5.2 æ‰‹åŠ¨æµ‹è¯•æ¸…å•
```
â˜ å®‰è£…ä½“éªŒï¼špip install opsai
â˜ é¦–æ¬¡è¿è¡Œï¼šopsai-tuiï¼ˆæ£€æŸ¥æ˜¯å¦æŠ¥é”™ï¼‰
â˜ æ ¸å¿ƒåœºæ™¯ï¼š
  â˜ æŸ¥çœ‹å®¹å™¨åˆ—è¡¨
  â˜ æŸ¥çœ‹æ—¥å¿—
  â˜ é‡å¯æœåŠ¡
  â˜ æ£€æŸ¥ç£ç›˜
â˜ ä¸€é”®éƒ¨ç½²ï¼šopsai deploy <github-url>
â˜ Dry-run æ¨¡å¼ï¼š--dry-run å‚æ•°
â˜ é…ç½®ç®¡ç†ï¼šopsai config show
```

#### 1.5.3 å‘å¸ƒ v0.2.0
```bash
# æ›´æ–°ç‰ˆæœ¬å·
# pyproject.toml: version = "0.2.0"

# ç¼–å†™ CHANGELOG
cat > CHANGELOG.md << 'EOF'
# Changelog

## [0.2.0] - 2026-02-XX

### ğŸš€ æ–°å¢
- ä¸€é”®éƒ¨ç½² GitHub é¡¹ç›®ï¼ˆ`opsai deploy <url>`ï¼‰
- æ™ºèƒ½é”™è¯¯æç¤ºï¼ˆå¤±è´¥æ—¶æä¾›å¯æ“ä½œå»ºè®®ï¼‰

### âœ¨ ä¼˜åŒ–
- ç²¾ç®€ Workers æ•°é‡ï¼ˆ10 â†’ 7 ä¸ªï¼‰
- ç®€åŒ– READMEï¼Œæ–°å¢"5 åˆ†é’Ÿå¿«é€Ÿä¸Šæ‰‹"
- å†…ç½®ç¼“å­˜é€»è¾‘ï¼ˆç§»é™¤ç‹¬ç«‹ CacheWorkerï¼‰

### ğŸ—‘ï¸ ç§»é™¤
- ç§»é™¤ Tavily æœç´¢ä¾èµ–ï¼ˆå‡å°‘å¤–éƒ¨ä¾èµ–ï¼‰

### ğŸ› ä¿®å¤
- ä¿®å¤ analyze æŒ‡ä»£è§£æé—®é¢˜
- ä¿®å¤ dry-run æ¨¡å¼ä¸‹çš„æ—¥å¿—è®°å½•

### ğŸ“ æ–‡æ¡£
- æ–°å¢æ¼”ç¤ºè§†é¢‘
- æ–°å¢åœºæ™¯åŒ–ç¤ºä¾‹
- æ–°å¢ FAQ æ–‡æ¡£
EOF

# æ„å»ºå‘å¸ƒ
uv build
uv publish  # æˆ– twine upload dist/*
```

**äº§å‡º**ï¼š
- âœ… æµ‹è¯•è¦†ç›–ç‡ > 80%
- âœ… å‘å¸ƒ v0.2.0
- âœ… æ›´æ–° CHANGELOG

---

## ğŸ¨ P1 é˜¶æ®µï¼šä½“éªŒä¼˜åŒ–ï¼ˆç¬¬ 3-6 å‘¨ï¼‰

**ç›®æ ‡**ï¼šè®©æ–°æ‰‹åœ¨ 5 åˆ†é’Ÿå†…èƒ½ç‹¬ç«‹å®Œæˆæ ¸å¿ƒæ“ä½œ

### Task 2.1ï¼šé¦–æ¬¡è¿è¡Œå¼•å¯¼ â±ï¸ 12 å°æ—¶

**ä¸ºä»€ä¹ˆåš**ï¼š
- æ–°æ‰‹ä¸çŸ¥é“ä»å“ªå¼€å§‹
- éœ€è¦"æ‰‹æŠŠæ‰‹æ•™"çš„ä½“éªŒ

**å…·ä½“æ­¥éª¤**ï¼š

#### 2.1.1 ç¯å¢ƒæ£€æµ‹å™¨
```python
# æ–‡ä»¶ï¼šsrc/context/detector.py (æ–°å»º)

from typing import Optional
import subprocess
from dataclasses import dataclass

@dataclass
class EnvironmentInfo:
    """ç¯å¢ƒä¿¡æ¯"""
    has_docker: bool
    docker_containers: int
    has_systemd: bool
    systemd_services: list[str]
    has_kubernetes: bool
    disk_usage: float  # ç™¾åˆ†æ¯”
    memory_usage: float

class EnvironmentDetector:
    """ç¯å¢ƒæ£€æµ‹å™¨"""
    
    def detect(self) -> EnvironmentInfo:
        """æ£€æµ‹å½“å‰ç¯å¢ƒ"""
        return EnvironmentInfo(
            has_docker=self._check_docker(),
            docker_containers=self._count_containers(),
            has_systemd=self._check_systemd(),
            systemd_services=self._list_important_services(),
            has_kubernetes=self._check_kubernetes(),
            disk_usage=self._get_disk_usage(),
            memory_usage=self._get_memory_usage(),
        )
    
    def _check_docker(self) -> bool:
        """æ£€æŸ¥ Docker æ˜¯å¦è¿è¡Œ"""
        try:
            result = subprocess.run(
                ["docker", "ps"],
                capture_output=True,
                timeout=2,
            )
            return result.returncode == 0
        except Exception:
            return False
    
    def _count_containers(self) -> int:
        """ç»Ÿè®¡å®¹å™¨æ•°é‡"""
        if not self._check_docker():
            return 0
        try:
            result = subprocess.run(
                ["docker", "ps", "-q"],
                capture_output=True,
                text=True,
                timeout=2,
            )
            return len(result.stdout.strip().split("\n")) if result.stdout.strip() else 0
        except Exception:
            return 0
    
    def _check_systemd(self) -> bool:
        """æ£€æŸ¥ Systemd æ˜¯å¦å¯ç”¨"""
        try:
            result = subprocess.run(
                ["systemctl", "--version"],
                capture_output=True,
                timeout=2,
            )
            return result.returncode == 0
        except Exception:
            return False
    
    def _list_important_services(self) -> list[str]:
        """åˆ—å‡ºé‡è¦çš„ systemd æœåŠ¡"""
        if not self._check_systemd():
            return []
        
        important_services = [
            "nginx", "apache2", "httpd",
            "mysql", "postgresql",
            "redis", "mongodb",
        ]
        
        running = []
        for service in important_services:
            try:
                result = subprocess.run(
                    ["systemctl", "is-active", service],
                    capture_output=True,
                    text=True,
                    timeout=1,
                )
                if result.stdout.strip() == "active":
                    running.append(service)
            except Exception:
                pass
        
        return running
    
    def _check_kubernetes(self) -> bool:
        """æ£€æŸ¥ Kubernetes æ˜¯å¦å¯ç”¨"""
        try:
            result = subprocess.run(
                ["kubectl", "version", "--client"],
                capture_output=True,
                timeout=2,
            )
            return result.returncode == 0
        except Exception:
            return False
    
    def _get_disk_usage(self) -> float:
        """è·å–æ ¹ç›®å½•ç£ç›˜ä½¿ç”¨ç‡"""
        try:
            result = subprocess.run(
                ["df", "-h", "/"],
                capture_output=True,
                text=True,
                timeout=2,
            )
            lines = result.stdout.strip().split("\n")
            if len(lines) >= 2:
                parts = lines[1].split()
                if len(parts) >= 5:
                    usage_str = parts[4].rstrip("%")
                    return float(usage_str)
        except Exception:
            pass
        return 0.0
    
    def _get_memory_usage(self) -> float:
        """è·å–å†…å­˜ä½¿ç”¨ç‡"""
        try:
            result = subprocess.run(
                ["free", "-m"],
                capture_output=True,
                text=True,
                timeout=2,
            )
            lines = result.stdout.strip().split("\n")
            if len(lines) >= 2:
                parts = lines[1].split()
                if len(parts) >= 3:
                    total = float(parts[1])
                    used = float(parts[2])
                    return (used / total) * 100
        except Exception:
            pass
        return 0.0
```

#### 2.1.2 æ¬¢è¿ç•Œé¢
```python
# æ–‡ä»¶ï¼šsrc/tui.py

from src.context.detector import EnvironmentDetector, EnvironmentInfo

class OpsAIApp(App):
    
    def on_mount(self) -> None:
        """åº”ç”¨å¯åŠ¨æ—¶"""
        # æ£€æŸ¥æ˜¯å¦é¦–æ¬¡è¿è¡Œ
        if self._is_first_run():
            self.show_welcome_wizard()
    
    def _is_first_run(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦é¦–æ¬¡è¿è¡Œ"""
        marker_file = Path.home() / ".opsai" / ".first_run_complete"
        return not marker_file.exists()
    
    def _mark_first_run_complete(self) -> None:
        """æ ‡è®°é¦–æ¬¡è¿è¡Œå·²å®Œæˆ"""
        marker_file = Path.home() / ".opsai" / ".first_run_complete"
        marker_file.parent.mkdir(parents=True, exist_ok=True)
        marker_file.touch()
    
    def show_welcome_wizard(self) -> None:
        """æ˜¾ç¤ºæ¬¢è¿å‘å¯¼"""
        detector = EnvironmentDetector()
        env_info = detector.detect()
        
        # æ„å»ºæ¬¢è¿æ¶ˆæ¯
        welcome_parts = [
            "ğŸ‰ æ¬¢è¿ä½¿ç”¨ OpsAIï¼",
            "",
            "æˆ‘å·²ç»æ£€æµ‹åˆ°ä½ çš„ç¯å¢ƒï¼š",
        ]
        
        # Docker ä¿¡æ¯
        if env_info.has_docker:
            welcome_parts.append(f"âœ“ Docker æ­£åœ¨è¿è¡Œ ({env_info.docker_containers} ä¸ªå®¹å™¨)")
        else:
            welcome_parts.append("âœ— Docker æœªè¿è¡Œ")
        
        # Systemd ä¿¡æ¯
        if env_info.has_systemd:
            if env_info.systemd_services:
                services_str = ", ".join(env_info.systemd_services[:3])
                welcome_parts.append(f"âœ“ Systemd æœåŠ¡ï¼š{services_str}...")
            else:
                welcome_parts.append("âœ“ Systemd æœåŠ¡ç®¡ç†å™¨")
        
        # Kubernetes ä¿¡æ¯
        if env_info.has_kubernetes:
            welcome_parts.append("âœ“ Kubernetes (kubectl)")
        
        # èµ„æºè­¦å‘Š
        welcome_parts.append("")
        if env_info.disk_usage > 80:
            welcome_parts.append(f"âš ï¸  ç£ç›˜ä½¿ç”¨ç‡ {env_info.disk_usage:.0f}%ï¼ˆå»ºè®®æ¸…ç†ï¼‰")
        
        if env_info.memory_usage > 80:
            welcome_parts.append(f"âš ï¸  å†…å­˜ä½¿ç”¨ç‡ {env_info.memory_usage:.0f}%")
        
        # æ¨èæ“ä½œ
        welcome_parts.extend([
            "",
            "æ¨èä½ è¯•è¯•è¿™äº›æ“ä½œï¼š",
        ])
        
        suggestions = self._generate_suggestions(env_info)
        for i, suggestion in enumerate(suggestions, 1):
            welcome_parts.append(f"{i}ï¸âƒ£  {suggestion}")
        
        welcome_parts.extend([
            "",
            "ğŸ’¡ æç¤ºï¼šç›´æ¥ç”¨è‡ªç„¶è¯­è¨€æè¿°ä½ çš„éœ€æ±‚å³å¯",
            "   ä¾‹å¦‚ï¼š"æŸ¥çœ‹æ—¥å¿—"ã€"é‡å¯æœåŠ¡"ã€"ç£ç›˜å¿«æ»¡äº†"",
        ])
        
        # æ˜¾ç¤ºæ¬¢è¿é¢æ¿
        welcome_msg = "\n".join(welcome_parts)
        self.add_message("system", welcome_msg)
        
        # æ ‡è®°é¦–æ¬¡è¿è¡Œå®Œæˆ
        self._mark_first_run_complete()
    
    def _generate_suggestions(self, env_info: EnvironmentInfo) -> list[str]:
        """æ ¹æ®ç¯å¢ƒç”Ÿæˆæ“ä½œå»ºè®®"""
        suggestions = []
        
        if env_info.has_docker and env_info.docker_containers > 0:
            suggestions.append("æŸ¥çœ‹æ‰€æœ‰å®¹å™¨çŠ¶æ€")
        
        if env_info.disk_usage > 70:
            suggestions.append("æŸ¥çœ‹ç£ç›˜ä½¿ç”¨æƒ…å†µ")
        
        if env_info.systemd_services:
            suggestions.append(f"æŸ¥çœ‹ {env_info.systemd_services[0]} æœåŠ¡æ—¥å¿—")
        elif env_info.has_docker:
            suggestions.append("æŸ¥çœ‹å®¹å™¨æ—¥å¿—")
        else:
            suggestions.append("æŸ¥çœ‹ç³»ç»Ÿæ—¥å¿—")
        
        # è‡³å°‘æä¾› 3 ä¸ªå»ºè®®
        if len(suggestions) < 3:
            suggestions.append("æ£€æŸ¥ç³»ç»Ÿèµ„æºå ç”¨")
        
        return suggestions[:3]
```

#### 2.1.3 æµ‹è¯•
```python
# æ–‡ä»¶ï¼štests/test_welcome_wizard.py

def test_environment_detection():
    """æµ‹è¯•ç¯å¢ƒæ£€æµ‹"""
    detector = EnvironmentDetector()
    env_info = detector.detect()
    
    assert isinstance(env_info.has_docker, bool)
    assert env_info.docker_containers >= 0
    assert env_info.disk_usage >= 0

def test_first_run_detection():
    """æµ‹è¯•é¦–æ¬¡è¿è¡Œæ£€æµ‹"""
    # åˆ é™¤æ ‡è®°æ–‡ä»¶
    marker_file = Path.home() / ".opsai" / ".first_run_complete"
    if marker_file.exists():
        marker_file.unlink()
    
    app = OpsAIApp()
    assert app._is_first_run()
    
    app._mark_first_run_complete()
    assert not app._is_first_run()
```

**äº§å‡º**ï¼š
- âœ… ç¯å¢ƒè‡ªåŠ¨æ£€æµ‹
- âœ… æ™ºèƒ½æ“ä½œæ¨è
- âœ… é¦–æ¬¡è¿è¡Œå¼•å¯¼

---

### Task 2.2ï¼šåœºæ™¯æ¨èç³»ç»Ÿ â±ï¸ 16 å°æ—¶

**å…·ä½“æ­¥éª¤**ï¼š

#### 2.2.1 åœºæ™¯å®šä¹‰
```python
# æ–‡ä»¶ï¼šsrc/orchestrator/scenarios.py (æ–°å»º)

from dataclasses import dataclass
from typing import Optional

@dataclass
class Scenario:
    """è¿ç»´åœºæ™¯"""
    id: str
    title: str
    description: str
    category: str  # troubleshooting, maintenance, deployment, monitoring
    icon: str
    steps: list[dict[str, str]]  # [{"prompt": "...", "description": "..."}]
    risk_level: str  # safe, medium, high

# é¢„ç½®åœºæ™¯åº“
SCENARIOS: list[Scenario] = [
    Scenario(
        id="service_down",
        title="æœåŠ¡æ— å“åº”",
        description="ç½‘ç«™/API æ‰“ä¸å¼€ï¼Œå¿«é€Ÿè¯Šæ–­å’Œä¿®å¤",
        category="troubleshooting",
        icon="ğŸ”´",
        steps=[
            {"prompt": "åˆ—å‡ºæ‰€æœ‰å®¹å™¨", "description": "æ£€æŸ¥æœåŠ¡æ˜¯å¦è¿è¡Œ"},
            {"prompt": "æŸ¥çœ‹æ—¥å¿—", "description": "æŸ¥æ‰¾é”™è¯¯ä¿¡æ¯"},
            {"prompt": "é‡å¯æœåŠ¡", "description": "å°è¯•æ¢å¤æœåŠ¡"},
        ],
        risk_level="medium",
    ),
    Scenario(
        id="disk_full",
        title="ç£ç›˜ç©ºé—´ä¸è¶³",
        description="æ¸…ç†å¤§æ–‡ä»¶å’Œæ—¥å¿—ï¼Œé‡Šæ”¾ç£ç›˜ç©ºé—´",
        category="maintenance",
        icon="ğŸ’¾",
        steps=[
            {"prompt": "æŸ¥çœ‹ç£ç›˜ä½¿ç”¨æƒ…å†µ", "description": "å®šä½å ç”¨é«˜çš„ç›®å½•"},
            {"prompt": "æŸ¥æ‰¾å¤§æ–‡ä»¶", "description": "æ‰¾å‡ºå¯æ¸…ç†çš„æ–‡ä»¶"},
            {"prompt": "æ¸…ç†æ—¥å¿—", "description": "åˆ é™¤æ—§æ—¥å¿—æ–‡ä»¶"},
        ],
        risk_level="medium",
    ),
    Scenario(
        id="high_cpu",
        title="CPU å ç”¨è¿‡é«˜",
        description="æ’æŸ¥èµ„æºå ç”¨ï¼Œä¼˜åŒ–æ€§èƒ½",
        category="troubleshooting",
        icon="ğŸ”¥",
        steps=[
            {"prompt": "æŸ¥çœ‹è¿›ç¨‹ CPU å ç”¨", "description": "æ‰¾å‡ºå ç”¨æœ€é«˜çš„è¿›ç¨‹"},
            {"prompt": "åˆ†æè¿›ç¨‹è¯¦æƒ…", "description": "äº†è§£è¿›ç¨‹ç”¨é€”"},
            {"prompt": "é‡å¯é«˜å ç”¨æœåŠ¡", "description": "å°è¯•æ¢å¤æ­£å¸¸"},
        ],
        risk_level="medium",
    ),
    Scenario(
        id="deploy_github",
        title="éƒ¨ç½² GitHub é¡¹ç›®",
        description="ä¸€é”®éƒ¨ç½²å¼€æºé¡¹ç›®åˆ°æœåŠ¡å™¨",
        category="deployment",
        icon="ğŸš€",
        steps=[
            {"prompt": "éƒ¨ç½²é¡¹ç›®", "description": "è‡ªåŠ¨å…‹éš†ã€é…ç½®ã€å¯åŠ¨"},
        ],
        risk_level="medium",
    ),
    Scenario(
        id="check_logs",
        title="æŸ¥çœ‹æœåŠ¡æ—¥å¿—",
        description="å¿«é€Ÿå®šä½é”™è¯¯å’Œå¼‚å¸¸",
        category="monitoring",
        icon="ğŸ“‹",
        steps=[
            {"prompt": "åˆ—å‡ºæ‰€æœ‰æœåŠ¡", "description": "é€‰æ‹©è¦æŸ¥çœ‹çš„æœåŠ¡"},
            {"prompt": "æŸ¥çœ‹æ—¥å¿—", "description": "æ˜¾ç¤ºæœ€è¿‘çš„æ—¥å¿—"},
        ],
        risk_level="safe",
    ),
]

class ScenarioManager:
    """åœºæ™¯ç®¡ç†å™¨"""
    
    def __init__(self):
        self._scenarios = {s.id: s for s in SCENARIOS}
    
    def get_by_id(self, scenario_id: str) -> Optional[Scenario]:
        """æ ¹æ® ID è·å–åœºæ™¯"""
        return self._scenarios.get(scenario_id)
    
    def get_by_category(self, category: str) -> list[Scenario]:
        """æ ¹æ®åˆ†ç±»è·å–åœºæ™¯"""
        return [s for s in SCENARIOS if s.category == category]
    
    def get_all(self) -> list[Scenario]:
        """è·å–æ‰€æœ‰åœºæ™¯"""
        return SCENARIOS
    
    def recommend(self, env_info: EnvironmentInfo) -> list[Scenario]:
        """æ ¹æ®ç¯å¢ƒæ¨èåœºæ™¯"""
        recommendations = []
        
        # ç£ç›˜å‘Šè­¦ â†’ æ¨èæ¸…ç†åœºæ™¯
        if env_info.disk_usage > 80:
            recommendations.append(self.get_by_id("disk_full"))
        
        # æœ‰ Docker å®¹å™¨ â†’ æ¨èæœåŠ¡ç®¡ç†
        if env_info.has_docker and env_info.docker_containers > 0:
            recommendations.append(self.get_by_id("service_down"))
            recommendations.append(self.get_by_id("check_logs"))
        
        # é»˜è®¤æ¨è
        if not recommendations:
            recommendations.extend([
                self.get_by_id("check_logs"),
                self.get_by_id("deploy_github"),
            ])
        
        return [s for s in recommendations if s]  # è¿‡æ»¤ None
```

#### 2.2.2 TUI åœºæ™¯ç•Œé¢
```python
# æ–‡ä»¶ï¼šsrc/tui.py

from src.orchestrator.scenarios import ScenarioManager

class OpsAIApp(App):
    
    def __init__(self):
        super().__init__()
        self._scenario_manager = ScenarioManager()
    
    def show_scenarios(self) -> None:
        """æ˜¾ç¤ºåœºæ™¯åˆ—è¡¨"""
        scenarios = self._scenario_manager.get_all()
        
        # æŒ‰åˆ†ç±»ç»„ç»‡
        categories = {
            "troubleshooting": "ğŸ”´ æ•…éšœæ’æŸ¥",
            "maintenance": "ğŸ› ï¸  æ—¥å¸¸ç»´æŠ¤",
            "deployment": "ğŸš€ é¡¹ç›®éƒ¨ç½²",
            "monitoring": "ğŸ“Š ç›‘æ§æŸ¥çœ‹",
        }
        
        message_parts = ["â•â•â• å¸¸è§è¿ç»´åœºæ™¯ â•â•â•\n"]
        
        for cat_id, cat_name in categories.items():
            cat_scenarios = self._scenario_manager.get_by_category(cat_id)
            if not cat_scenarios:
                continue
            
            message_parts.append(f"\n{cat_name}")
            for scenario in cat_scenarios:
                risk_badge = {
                    "safe": "ğŸŸ¢",
                    "medium": "ğŸŸ¡",
                    "high": "ğŸ”´",
                }.get(scenario.risk_level, "")
                
                message_parts.append(
                    f"  {scenario.icon} [{scenario.id}] {scenario.title} {risk_badge}"
                )
                message_parts.append(f"     {scenario.description}")
        
        message_parts.extend([
            "",
            "ğŸ’¡ ä½¿ç”¨æ–¹æ³•ï¼š",
            "   - è¾“å…¥åœºæ™¯ IDï¼ˆå¦‚ 'service_down'ï¼‰å¿«é€Ÿæ‰§è¡Œ",
            "   - æˆ–ç›´æ¥æè¿°ä½ çš„é—®é¢˜ï¼ˆå¦‚ 'æœåŠ¡æ‰“ä¸å¼€'ï¼‰",
        ])
        
        self.add_message("system", "\n".join(message_parts))
    
    async def handle_input(self, user_input: str) -> None:
        """å¤„ç†ç”¨æˆ·è¾“å…¥"""
        # æ£€æŸ¥æ˜¯å¦æ˜¯åœºæ™¯ ID
        scenario = self._scenario_manager.get_by_id(user_input.strip().lower())
        if scenario:
            await self._execute_scenario(scenario)
            return
        
        # å¦åˆ™èµ°æ­£å¸¸çš„ LLM å¤„ç†æµç¨‹
        await self._process_normal_query(user_input)
    
    async def _execute_scenario(self, scenario: Scenario) -> None:
        """æ‰§è¡Œåœºæ™¯"""
        self.add_message("system", f"å¼€å§‹æ‰§è¡Œåœºæ™¯ï¼š{scenario.icon} {scenario.title}")
        
        for i, step in enumerate(scenario.steps, 1):
            self.add_message("system", f"Step {i}/{len(scenario.steps)}: {step['description']}")
            
            # æ‰§è¡Œæ­¥éª¤
            await self._process_normal_query(step["prompt"])
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦ç”¨æˆ·ç¡®è®¤ç»§ç»­
            if i < len(scenario.steps):
                # TODO: æ·»åŠ "ç»§ç»­ä¸‹ä¸€æ­¥"çš„ç¡®è®¤é€»è¾‘
                pass
        
        self.add_message("system", f"âœ… åœºæ™¯æ‰§è¡Œå®Œæˆï¼š{scenario.title}")
```

#### 2.2.3 CLI åœºæ™¯å‘½ä»¤
```python
# æ–‡ä»¶ï¼šsrc/cli.py

@app.command()
def scenarios():
    """åˆ—å‡ºæ‰€æœ‰å¯ç”¨åœºæ™¯"""
    from src.orchestrator.scenarios import ScenarioManager
    from rich.table import Table
    
    console = Console()
    manager = ScenarioManager()
    
    table = Table(title="OpsAI è¿ç»´åœºæ™¯")
    table.add_column("ID", style="cyan")
    table.add_column("æ ‡é¢˜", style="green")
    table.add_column("æè¿°")
    table.add_column("é£é™©", justify="center")
    
    for scenario in manager.get_all():
        risk_badge = {
            "safe": "ğŸŸ¢ å®‰å…¨",
            "medium": "ğŸŸ¡ ä¸­ç­‰",
            "high": "ğŸ”´ é«˜å±",
        }.get(scenario.risk_level, "")
        
        table.add_row(
            scenario.id,
            f"{scenario.icon} {scenario.title}",
            scenario.description,
            risk_badge,
        )
    
    console.print(table)
    console.print("\nğŸ’¡ ä½¿ç”¨ [cyan]opsai scenario <id>[/cyan] æ‰§è¡Œåœºæ™¯")

@app.command()
def scenario(
    scenario_id: str = typer.Argument(..., help="åœºæ™¯ ID"),
    dry_run: bool = typer.Option(False, "--dry-run", help="æ¨¡æ‹Ÿæ‰§è¡Œ"),
):
    """æ‰§è¡Œé¢„å®šä¹‰åœºæ™¯
    
    ç¤ºä¾‹ï¼š
        opsai scenario disk_full
        opsai scenario service_down --dry-run
    """
    from src.orchestrator.scenarios import ScenarioManager
    
    console = Console()
    manager = ScenarioManager()
    
    scenario = manager.get_by_id(scenario_id)
    if not scenario:
        console.print(f"[red]é”™è¯¯ï¼šæœªæ‰¾åˆ°åœºæ™¯ '{scenario_id}'[/red]")
        console.print("ä½¿ç”¨ [cyan]opsai scenarios[/cyan] æŸ¥çœ‹æ‰€æœ‰å¯ç”¨åœºæ™¯")
        raise typer.Exit(code=1)
    
    console.print(Panel(
        f"{scenario.icon} {scenario.title}\n\n{scenario.description}",
        title="æ‰§è¡Œåœºæ™¯",
        border_style="green",
    ))
    
    # æ‰§è¡Œåœºæ™¯æ­¥éª¤
    for i, step in enumerate(scenario.steps, 1):
        console.print(f"\n[bold]Step {i}/{len(scenario.steps)}:[/bold] {step['description']}")
        
        # è°ƒç”¨ query å‘½ä»¤æ‰§è¡Œæ­¥éª¤
        # TODO: å®ç°æ­¥éª¤æ‰§è¡Œé€»è¾‘
        console.print(f"  æ‰§è¡Œ: {step['prompt']}")
```

**äº§å‡º**ï¼š
- âœ… 5 ä¸ªé¢„ç½®åœºæ™¯
- âœ… TUI åœºæ™¯ç•Œé¢
- âœ… CLI åœºæ™¯å‘½ä»¤
- âœ… æ™ºèƒ½åœºæ™¯æ¨è

---

### Task 2.3ï¼šæ™ºèƒ½é”™è¯¯æç¤º â±ï¸ 8 å°æ—¶

**å…·ä½“æ­¥éª¤**ï¼š

#### 2.3.1 é”™è¯¯åˆ†æå™¨
```python
# æ–‡ä»¶ï¼šsrc/orchestrator/error_helper.py (æ–°å»º)

from typing import Optional
from src.types import WorkerResult

class ErrorHelper:
    """é”™è¯¯æç¤ºåŠ©æ‰‹"""
    
    def suggest_fix(self, result: WorkerResult, user_input: str) -> Optional[str]:
        """æ ¹æ®é”™è¯¯ç»“æœç”Ÿæˆå»ºè®®
        
        Args:
            result: Worker æ‰§è¡Œç»“æœ
            user_input: ç”¨æˆ·åŸå§‹è¾“å…¥
        
        Returns:
            å»ºè®®æ–‡æœ¬ï¼ˆå¦‚æœæœ‰ï¼‰
        """
        if result.success:
            return None
        
        error_msg = result.message.lower()
        suggestions = []
        
        # å®¹å™¨æœªæ‰¾åˆ°
        if "not found" in error_msg and ("container" in error_msg or "docker" in error_msg):
            suggestions.extend([
                "ğŸ’¡ å¯èƒ½çš„åŸå› ï¼š",
                "  1. å®¹å™¨åç§°é”™è¯¯ï¼Œä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æŸ¥çœ‹æ‰€æœ‰å®¹å™¨ï¼š",
                "     opsai query \"åˆ—å‡ºæ‰€æœ‰å®¹å™¨\"",
                "  2. å¦‚æœæ˜¯ systemd æœåŠ¡ï¼Œå°è¯•ï¼š",
                "     opsai query \"æŸ¥çœ‹ æœåŠ¡å.service çŠ¶æ€\"",
                "  3. å¦‚æœæ˜¯è¿›ç¨‹ï¼Œå°è¯•ï¼š",
                "     opsai query \"æŸ¥çœ‹è¿›ç¨‹åˆ—è¡¨\"",
            ])
        
        # æƒé™ä¸è¶³
        elif "permission denied" in error_msg:
            suggestions.extend([
                "ğŸ’¡ æƒé™ä¸è¶³ï¼Œå°è¯•ä»¥ä¸‹æ–¹æ³•ï¼š",
                "  1. æ£€æŸ¥æ–‡ä»¶/ç›®å½•æƒé™ï¼š",
                "     ls -la <æ–‡ä»¶è·¯å¾„>",
                "  2. å¦‚æœéœ€è¦ root æƒé™ï¼Œä½¿ç”¨ sudoï¼š",
                "     sudo opsai query \"...\"",
                "  3. å¯¹äº Dockerï¼Œç¡®ä¿ç”¨æˆ·åœ¨ docker ç»„ï¼š",
                "     sudo usermod -aG docker $USER",
            ])
        
        # ç«¯å£å ç”¨
        elif "address already in use" in error_msg or "port" in error_msg:
            # å°è¯•ä»é”™è¯¯ä¿¡æ¯æå–ç«¯å£å·
            import re
            port_match = re.search(r":(\d+)", error_msg)
            port = port_match.group(1) if port_match else "ç«¯å£å·"
            
            suggestions.extend([
                f"ğŸ’¡ ç«¯å£ {port} å·²è¢«å ç”¨ï¼Œå°è¯•ä»¥ä¸‹æ–¹æ³•ï¼š",
                f"  1. æŸ¥çœ‹å ç”¨ç«¯å£çš„è¿›ç¨‹ï¼š",
                f"     opsai query \"æŸ¥çœ‹ {port} ç«¯å£å ç”¨\"",
                f"  2. åœæ­¢å ç”¨è¿›ç¨‹åé‡è¯•",
                f"  3. ä¿®æ”¹æœåŠ¡é…ç½®ï¼Œä½¿ç”¨å…¶ä»–ç«¯å£",
            ])
        
        # æ–‡ä»¶ä¸å­˜åœ¨
        elif "no such file" in error_msg or "not found" in error_msg:
            suggestions.extend([
                "ğŸ’¡ æ–‡ä»¶/ç›®å½•ä¸å­˜åœ¨ï¼Œå°è¯•ä»¥ä¸‹æ–¹æ³•ï¼š",
                "  1. æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®ï¼ˆæ³¨æ„å¤§å°å†™ï¼‰",
                "  2. æŸ¥çœ‹å½“å‰ç›®å½•å†…å®¹ï¼š",
                "     opsai query \"åˆ—å‡ºå½“å‰ç›®å½•æ–‡ä»¶\"",
                "  3. æœç´¢æ–‡ä»¶ä½ç½®ï¼š",
                "     opsai query \"æŸ¥æ‰¾æ–‡ä»¶ <æ–‡ä»¶å>\"",
            ])
        
        # Docker æœªè¿è¡Œ
        elif "cannot connect to the docker daemon" in error_msg:
            suggestions.extend([
                "ğŸ’¡ Docker æœªè¿è¡Œï¼Œå°è¯•ä»¥ä¸‹æ–¹æ³•ï¼š",
                "  1. å¯åŠ¨ Dockerï¼š",
                "     sudo systemctl start docker",
                "  2. æ£€æŸ¥ Docker çŠ¶æ€ï¼š",
                "     sudo systemctl status docker",
                "  3. å¦‚æœæ˜¯ macOS/Windowsï¼Œå¯åŠ¨ Docker Desktop",
            ])
        
        # å‘½ä»¤æœªæ‰¾åˆ°
        elif "command not found" in error_msg:
            cmd_match = re.search(r"command not found: (\w+)", error_msg)
            cmd = cmd_match.group(1) if cmd_match else "å‘½ä»¤"
            
            suggestions.extend([
                f"ğŸ’¡ å‘½ä»¤ '{cmd}' æœªå®‰è£…ï¼Œå°è¯•ä»¥ä¸‹æ–¹æ³•ï¼š",
                f"  1. å®‰è£…å‘½ä»¤ï¼ˆæ ¹æ®ç³»ç»Ÿï¼‰ï¼š",
                f"     apt install {cmd}  # Debian/Ubuntu",
                f"     yum install {cmd}  # CentOS/RHEL",
                f"     brew install {cmd}  # macOS",
                f"  2. æ£€æŸ¥å‘½ä»¤æ˜¯å¦åœ¨ PATH ä¸­",
            ])
        
        # é€šç”¨å»ºè®®
        if not suggestions:
            suggestions.extend([
                "ğŸ’¡ æ“ä½œå¤±è´¥ï¼Œå»ºè®®ï¼š",
                "  1. æ£€æŸ¥è¾“å…¥æ˜¯å¦æ­£ç¡®",
                "  2. ä½¿ç”¨ --dry-run é¢„è§ˆæ“ä½œ",
                "  3. æŸ¥çœ‹å®¡è®¡æ—¥å¿—äº†è§£è¯¦æƒ…ï¼š",
                "     cat ~/.opsai/audit.log",
            ])
        
        return "\n".join(suggestions)
```

#### 2.3.2 é›†æˆåˆ° Orchestrator
```python
# æ–‡ä»¶ï¼šsrc/orchestrator/engine.py

from src.orchestrator.error_helper import ErrorHelper

class Orchestrator:
    
    def __init__(self, ...):
        # ...
        self._error_helper = ErrorHelper()
    
    async def react_loop(self, user_input: str, ...) -> WorkerResult:
        # ... åŸæœ‰é€»è¾‘ ...
        
        # æ‰§è¡Œ Worker
        result = await worker.execute(action, args)
        
        # å¦‚æœå¤±è´¥ï¼Œç”Ÿæˆå»ºè®®
        if not result.success:
            suggestions = self._error_helper.suggest_fix(result, user_input)
            if suggestions:
                # å°†å»ºè®®é™„åŠ åˆ°é”™è¯¯æ¶ˆæ¯
                result.message = f"{result.message}\n\n{suggestions}"
        
        return result
```

**äº§å‡º**ï¼š
- âœ… æ™ºèƒ½é”™è¯¯æç¤º
- âœ… 7 ç§å¸¸è§é”™è¯¯åœºæ™¯è¦†ç›–
- âœ… å¯æ“ä½œçš„å»ºè®®

---

### Task 2.4ï¼šæ–‡æ¡£ä¼˜åŒ– â±ï¸ 8 å°æ—¶

#### 2.4.1 åˆ›å»ºå¿«é€Ÿä¸Šæ‰‹æ–‡æ¡£
```bash
mkdir -p docs/quickstart
```

```markdown
# æ–‡ä»¶ï¼šdocs/quickstart/5min-guide.md

# 5 åˆ†é’Ÿå¿«é€Ÿä¸Šæ‰‹æŒ‡å—

## ç¬¬ 1 åˆ†é’Ÿï¼šå®‰è£…

```bash
pip install opsai
```

## ç¬¬ 2 åˆ†é’Ÿï¼šå¯åŠ¨

```bash
opsai-tui
```

ä½ ä¼šçœ‹åˆ°æ¬¢è¿ç•Œé¢ï¼Œæ˜¾ç¤ºæ£€æµ‹åˆ°çš„ç¯å¢ƒä¿¡æ¯ã€‚

## ç¬¬ 3 åˆ†é’Ÿï¼šè¯•è¯•è¿™ 3 ä¸ªå‘½ä»¤

### 1. æŸ¥çœ‹æ‰€æœ‰å®¹å™¨
```
> æŸ¥çœ‹æ‰€æœ‰å®¹å™¨
```

### 2. æŸ¥çœ‹ç£ç›˜ç©ºé—´
```
> æŸ¥çœ‹ç£ç›˜ä½¿ç”¨æƒ…å†µ
```

### 3. æŸ¥çœ‹æ—¥å¿—
```
> æŸ¥çœ‹æœ€è¿‘çš„æ—¥å¿—
```

## ç¬¬ 4 åˆ†é’Ÿï¼šå°è¯•æŒ‡ä»£è§£æ

```
> åˆ—å‡ºæ‰€æœ‰å®¹å™¨
> è¿™ä¸ªæ˜¯å¹²å˜›çš„  â† è‡ªåŠ¨è§£æä¸ºä¸Šä¸€æ­¥çš„å®¹å™¨
```

## ç¬¬ 5 åˆ†é’Ÿï¼šæ¢ç´¢åœºæ™¯

```
> scenarios  â† æŸ¥çœ‹æ‰€æœ‰é¢„ç½®åœºæ™¯
> service_down  â† æ‰§è¡Œ"æœåŠ¡æ— å“åº”"åœºæ™¯
```

---

## ä¸‹ä¸€æ­¥

- [å¸¸è§åœºæ™¯ç¤ºä¾‹](scenarios.md)
- [é…ç½® LLM](../configuration/llm.md)
- [å®‰å…¨æœºåˆ¶è¯¦è§£](../features/safety.md)
```

#### 2.4.2 åœºæ™¯ç¤ºä¾‹æ–‡æ¡£
```markdown
# æ–‡ä»¶ï¼šdocs/quickstart/scenarios.md

# å¸¸è§è¿ç»´åœºæ™¯

## ğŸ”´ åœºæ™¯ 1ï¼šæœåŠ¡æ— å“åº”

**é—®é¢˜**ï¼šç½‘ç«™/API æ‰“ä¸å¼€

**æ“ä½œæ­¥éª¤**ï¼š

```bash
# æ–¹å¼ 1ï¼šä½¿ç”¨åœºæ™¯ ID
opsai scenario service_down

# æ–¹å¼ 2ï¼šè‡ªç„¶è¯­è¨€æè¿°
opsai-tui
> "æˆ‘çš„ç½‘ç«™æ‰“ä¸å¼€äº†"
```

**è‡ªåŠ¨æ‰§è¡Œ**ï¼š
1. æ£€æŸ¥å®¹å™¨/è¿›ç¨‹çŠ¶æ€
2. æŸ¥çœ‹æœ€è¿‘çš„é”™è¯¯æ—¥å¿—
3. è¯¢é—®æ˜¯å¦é‡å¯æœåŠ¡

---

## ğŸ’¾ åœºæ™¯ 2ï¼šç£ç›˜ç©ºé—´ä¸è¶³

**é—®é¢˜**ï¼šæœåŠ¡å™¨æç¤º "No space left on device"

**æ“ä½œæ­¥éª¤**ï¼š

```bash
opsai scenario disk_full
```

**è‡ªåŠ¨æ‰§è¡Œ**ï¼š
1. æŸ¥çœ‹å„åˆ†åŒºä½¿ç”¨æƒ…å†µ
2. æŸ¥æ‰¾å¤§äº 100MB çš„æ–‡ä»¶
3. å»ºè®®å¯æ¸…ç†çš„æ—¥å¿—/ä¸´æ—¶æ–‡ä»¶
4. è¯¢é—®æ˜¯å¦æ‰§è¡Œæ¸…ç†

---

## ğŸŒ åœºæ™¯ 3ï¼šæœåŠ¡å“åº”æ…¢

**é—®é¢˜**ï¼šAPI å“åº”æ—¶é—´ä» 100ms å¢åŠ åˆ° 5s

**æ“ä½œæ­¥éª¤**ï¼š

```bash
opsai-tui
> "æœåŠ¡å¾ˆæ…¢ï¼Œå¸®æˆ‘çœ‹çœ‹"
```

**è‡ªåŠ¨æ‰§è¡Œ**ï¼š
1. æ£€æŸ¥ CPU/å†…å­˜å ç”¨
2. æŸ¥çœ‹å®¹å™¨èµ„æºé™åˆ¶
3. åˆ†ææ—¥å¿—ä¸­çš„æ…¢æŸ¥è¯¢
4. å»ºè®®ä¼˜åŒ–æ–¹æ¡ˆï¼ˆé‡å¯/æ‰©å®¹/ä¼˜åŒ–ï¼‰

---

## ğŸš€ åœºæ™¯ 4ï¼šéƒ¨ç½² GitHub é¡¹ç›®

**é—®é¢˜**ï¼šæƒ³å¿«é€Ÿéƒ¨ç½²ä¸€ä¸ªå¼€æºé¡¹ç›®

**æ“ä½œæ­¥éª¤**ï¼š

```bash
# ä¸€é”®éƒ¨ç½²
opsai deploy https://github.com/user/my-app

# æˆ–é€šè¿‡ TUI
opsai-tui
> "å¸®æˆ‘éƒ¨ç½² https://github.com/user/my-app"
```

**è‡ªåŠ¨æ‰§è¡Œ**ï¼š
1. åˆ†æé¡¹ç›®ç±»å‹ï¼ˆDocker/Python/Node.jsï¼‰
2. å…‹éš†ä»“åº“
3. å®‰è£…ä¾èµ–
4. å¯åŠ¨æœåŠ¡

---

## ğŸ“‹ åœºæ™¯ 5ï¼šæŸ¥çœ‹æœåŠ¡æ—¥å¿—

**é—®é¢˜**ï¼šéœ€è¦æ’æŸ¥é”™è¯¯ï¼Œä½†ä¸è®°å¾—æ—¥å¿—è·¯å¾„

**æ“ä½œæ­¥éª¤**ï¼š

```bash
opsai-tui
> "æŸ¥çœ‹ api-server çš„æ—¥å¿—"
```

**è‡ªåŠ¨æ‰§è¡Œ**ï¼š
1. è‡ªåŠ¨è¯†åˆ«æœåŠ¡ç±»å‹ï¼ˆDocker/Systemdï¼‰
2. è·å–æœ€è¿‘ 100 è¡Œæ—¥å¿—
3. é«˜äº®é”™è¯¯/è­¦å‘Šä¿¡æ¯
```

#### 2.4.3 FAQ æ–‡æ¡£
```markdown
# æ–‡ä»¶ï¼šdocs/quickstart/faq.md

# å¸¸è§é—®é¢˜

## å®‰è£…ä¸é…ç½®

### Q: å¦‚ä½•å®‰è£… OpsAIï¼Ÿ
```bash
pip install opsai
```

### Q: æ”¯æŒå“ªäº› Python ç‰ˆæœ¬ï¼Ÿ
Python 3.9 åŠä»¥ä¸Šã€‚

### Q: å¦‚ä½•é…ç½® LLMï¼Ÿ

**ä½¿ç”¨æœ¬åœ° Ollamaï¼ˆæ¨èï¼‰**ï¼š
```bash
# 1. å®‰è£… Ollama
curl -fsSL https://ollama.com/install.sh | sh

# 2. æ‹‰å–æ¨¡å‹
ollama pull qwen2.5:7b

# 3. é…ç½® OpsAI
opsai config set-llm --model qwen2.5:7b --base-url http://localhost:11434/v1
```

**ä½¿ç”¨ OpenAI**ï¼š
```bash
opsai config set-llm --model gpt-4o --api-key sk-xxx
```

---

## ä½¿ç”¨é—®é¢˜

### Q: æ”¯æŒå“ªäº›è¿ç»´å·¥å…·ï¼Ÿ
- âœ… Dockerï¼ˆå®¹å™¨ç®¡ç†ï¼‰
- âœ… Systemdï¼ˆæœåŠ¡ç®¡ç†ï¼‰
- âœ… é€šç”¨ Shell å‘½ä»¤
- ğŸš§ Kubernetesï¼ˆå¼€å‘ä¸­ï¼‰

### Q: éœ€è¦ root æƒé™å—ï¼Ÿ
ä¸éœ€è¦ã€‚OpsAI ç»§æ‰¿å½“å‰ç”¨æˆ·æƒé™ï¼Œä¸æ¶‰åŠææƒæ“ä½œã€‚

### Q: æ•°æ®å®‰å…¨å—ï¼Ÿ
- æ‰€æœ‰å‘½ä»¤åœ¨æœ¬åœ°æ‰§è¡Œ
- å®¡è®¡æ—¥å¿—å­˜å‚¨åœ¨ `~/.opsai/audit.log`
- ä»… LLM API è°ƒç”¨ä¼šå‘é€æ•°æ®ï¼ˆç¬¦åˆå„ API æä¾›å•†çš„éšç§æ”¿ç­–ï¼‰

### Q: å¦‚ä½•æŸ¥çœ‹å†å²æ“ä½œï¼Ÿ
```bash
# æŸ¥çœ‹å®¡è®¡æ—¥å¿—
cat ~/.opsai/audit.log

# æˆ–åœ¨ TUI ä¸­æŸ¥çœ‹å¯¹è¯å†å²
opsai-tui â†’ æŒ‰ä¸Šä¸‹ç®­å¤´æŸ¥çœ‹
```

---

## åŠŸèƒ½é—®é¢˜

### Q: å¦‚ä½•æ’¤é”€è¯¯æ“ä½œï¼Ÿ
OpsAI ä¸æä¾›è‡ªåŠ¨æ’¤é”€åŠŸèƒ½ï¼Œå»ºè®®ï¼š
1. ä½¿ç”¨ `--dry-run` é¢„è§ˆæ“ä½œ
2. å¯¹äºç ´åæ€§æ“ä½œï¼Œä¼šå¼ºåˆ¶äºŒæ¬¡ç¡®è®¤
3. æŸ¥çœ‹å®¡è®¡æ—¥å¿—äº†è§£å…·ä½“æ‰§è¡Œçš„å‘½ä»¤

### Q: Dry-run æ¨¡å¼æ˜¯ä»€ä¹ˆï¼Ÿ
æ¨¡æ‹Ÿæ‰§è¡Œæ¨¡å¼ï¼Œæ˜¾ç¤ºå°†è¦æ‰§è¡Œçš„æ“ä½œä½†ä¸å®é™…æ‰§è¡Œã€‚

```bash
# CLI æ¨¡å¼
opsai query "åˆ é™¤ä¸´æ—¶æ–‡ä»¶" --dry-run

# TUI æ¨¡å¼ä¼šè‡ªåŠ¨æç¤ºé«˜å±æ“ä½œ
```

### Q: å¦‚ä½•è‡ªå®šä¹‰åœºæ™¯ï¼Ÿ
åœºæ™¯å­˜å‚¨åœ¨ `~/.opsai/scenarios/`ï¼Œæ ¼å¼ä¸º JSONï¼š

```json
{
  "id": "my_scenario",
  "title": "æˆ‘çš„è‡ªå®šä¹‰åœºæ™¯",
  "description": "æè¿°",
  "category": "custom",
  "icon": "ğŸ¯",
  "steps": [
    {"prompt": "æŸ¥çœ‹çŠ¶æ€", "description": "æ£€æŸ¥æœåŠ¡"}
  ],
  "risk_level": "safe"
}
```

---

## æ•…éšœæ’é™¤

### Q: æç¤º "LLM connection failed"
1. æ£€æŸ¥ LLM é…ç½®ï¼š`opsai config show`
2. æµ‹è¯•è¿æ¥ï¼š`curl http://localhost:11434/v1/models`ï¼ˆOllamaï¼‰
3. æŸ¥çœ‹é”™è¯¯æ—¥å¿—ï¼š`~/.opsai/debug.log`

### Q: æç¤º "Docker daemon not running"
1. å¯åŠ¨ Dockerï¼š`sudo systemctl start docker`
2. æ£€æŸ¥çŠ¶æ€ï¼š`sudo systemctl status docker`
3. å¦‚æœæ˜¯ macOS/Windowsï¼Œå¯åŠ¨ Docker Desktop

### Q: å¦‚ä½•å¸è½½ï¼Ÿ
```bash
# 1. å¸è½½ Python åŒ…
pip uninstall opsai

# 2. åˆ é™¤é…ç½®æ–‡ä»¶
rm -rf ~/.opsai/
```

---

## è´¡çŒ®ä¸æ”¯æŒ

### Q: å¦‚ä½•æŠ¥å‘Š Bugï¼Ÿ
åœ¨ GitHub æäº¤ Issueï¼šhttps://github.com/yourusername/opsai/issues

### Q: å¦‚ä½•è´¡çŒ®ä»£ç ï¼Ÿ
å‚è§ [è´¡çŒ®æŒ‡å—](../CONTRIBUTING.md)

### Q: å¦‚ä½•è”ç³»å¼€å‘è€…ï¼Ÿ
- GitHub Issues
- Email: your-email@example.com
```

**äº§å‡º**ï¼š
- âœ… 5 åˆ†é’Ÿå¿«é€Ÿä¸Šæ‰‹æŒ‡å—
- âœ… åœºæ™¯ç¤ºä¾‹æ–‡æ¡£
- âœ… FAQ æ–‡æ¡£

---

## ğŸš€ P2 é˜¶æ®µï¼šåŠŸèƒ½å¢å¼ºï¼ˆç¬¬ 7-8 å‘¨ï¼Œå¯é€‰ï¼‰

### Task 3.1ï¼šTUI å¯è§†åŒ–å¢å¼º â±ï¸ 16 å°æ—¶

**å…·ä½“å†…å®¹**ï¼š
- å®¹å™¨/è¿›ç¨‹åˆ—è¡¨ç”¨è¡¨æ ¼å±•ç¤ºï¼ˆä½¿ç”¨ rich.tableï¼‰
- æ—¥å¿—é«˜äº®å…³é”®è¯ï¼ˆERROR, WARN, Exceptionï¼‰
- èµ„æºå ç”¨ç”¨è¿›åº¦æ¡å±•ç¤ºï¼ˆCPU/å†…å­˜/ç£ç›˜ï¼‰

### Task 3.2ï¼šå†å²è®°å½•å’Œæ”¶è— â±ï¸ 12 å°æ—¶

**å…·ä½“å†…å®¹**ï¼š
- ä¿å­˜å¸¸ç”¨æ“ä½œä¸ºä¹¦ç­¾
- å¿«é€Ÿè°ƒç”¨å†å²å‘½ä»¤
- å¯¼å‡º/å¯¼å…¥ä¹¦ç­¾é…ç½®

---

## ğŸ“Š éªŒæ”¶æ ‡å‡†

### P0 é˜¶æ®µéªŒæ”¶
- [ ] ä»£ç è¡Œæ•°å‡å°‘ > 500 è¡Œ
- [ ] Workers æ•°é‡ï¼š10 â†’ 7
- [ ] å¤–éƒ¨ä¾èµ–å‡å°‘ï¼š1 ä¸ªï¼ˆtavily-pythonï¼‰
- [ ] æ–°å¢ CLI å‘½ä»¤ï¼š`opsai deploy`
- [ ] README é•¿åº¦ï¼š200 è¡Œ â†’ 100 è¡Œ
- [ ] æµ‹è¯•è¦†ç›–ç‡ > 80%

### P1 é˜¶æ®µéªŒæ”¶
- [ ] é¦–æ¬¡è¿è¡Œæ˜¾ç¤ºæ¬¢è¿ç•Œé¢
- [ ] ç¯å¢ƒè‡ªåŠ¨æ£€æµ‹å‡†ç¡®ç‡ > 90%
- [ ] é¢„ç½®åœºæ™¯æ•°é‡ >= 5 ä¸ª
- [ ] é”™è¯¯æç¤ºè¦†ç›– 7 ç§å¸¸è§åœºæ™¯
- [ ] æ–°å¢å¿«é€Ÿä¸Šæ‰‹æ–‡æ¡£ 3 ç¯‡

### P2 é˜¶æ®µéªŒæ”¶
- [ ] TUI æ”¯æŒè¡¨æ ¼å±•ç¤º
- [ ] æ—¥å¿—é«˜äº®åŠŸèƒ½
- [ ] ä¹¦ç­¾ç³»ç»Ÿå¯ç”¨

---

## ğŸ¯ æˆåŠŸæŒ‡æ ‡

**äº§å“ç›®æ ‡**ï¼šè®©ä¸æ‡‚è¿ç»´çš„äººï¼Œåœ¨ 5 åˆ†é’Ÿå†…èƒ½ç‹¬ç«‹å®Œæˆï¼š

1. âœ… æŸ¥çœ‹æœåŠ¡çŠ¶æ€ï¼ˆç›®æ ‡ï¼š< 3 åˆ†é’Ÿï¼‰
2. âœ… æŸ¥çœ‹æ—¥å¿—æ‰¾é—®é¢˜ï¼ˆç›®æ ‡ï¼š< 5 åˆ†é’Ÿï¼‰
3. âœ… é‡å¯æœåŠ¡è§£å†³æ•…éšœï¼ˆç›®æ ‡ï¼š< 5 åˆ†é’Ÿï¼‰

**è¡¡é‡æ–¹å¼**ï¼š
- é‚€è¯· 5-10 ä¸ª"ä¸æ‡‚è¿ç»´çš„ç”¨æˆ·"è¯•ç”¨
- è®°å½•é¦–æ¬¡æˆåŠŸæ“ä½œæ—¶é—´
- æ”¶é›†ç”¨æˆ·åé¦ˆå’Œæ”¹è¿›å»ºè®®

---

## ğŸ“ æ€»ç»“

**æ€»å·¥æœŸ**ï¼š6-8 å‘¨  
**æ ¸å¿ƒåŸåˆ™**ï¼šå‡æ³•è€ŒéåŠ æ³•ï¼Œåœºæ™¯è€ŒéåŠŸèƒ½ï¼Œå¼•å¯¼è€Œéæ–‡æ¡£

**å…³é”®é‡Œç¨‹ç¢‘**ï¼š
- Week 2: å‘å¸ƒ v0.2.0ï¼ˆæ ¸å¿ƒç²¾ç®€ç‰ˆï¼‰
- Week 4: å‘å¸ƒ v0.3.0ï¼ˆä½“éªŒä¼˜åŒ–ç‰ˆï¼‰
- Week 6: å‘å¸ƒ v0.4.0ï¼ˆåŠŸèƒ½å¢å¼ºç‰ˆï¼‰

**ä¸‹ä¸€æ­¥**ï¼š
å»ºè®®å…ˆå®Œæˆ P0 é˜¶æ®µï¼ˆç¬¬ 1-2 å‘¨ï¼‰ï¼Œç„¶åé‚€è¯·çœŸå®ç”¨æˆ·è¯•ç”¨ï¼Œæ ¹æ®åé¦ˆè°ƒæ•´ P1/P2 çš„ä¼˜å…ˆçº§ã€‚
