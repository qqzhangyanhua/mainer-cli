"""ReAct å¾ªç¯å¼•æ“"""

from __future__ import annotations

from typing import Callable, Optional

from src.config.manager import OpsAIConfig
from src.context.environment import EnvironmentContext
from src.llm.client import LLMClient
from src.orchestrator.prompt import PromptBuilder
from src.orchestrator.safety import check_safety
from src.types import ConversationEntry, Instruction, RiskLevel, WorkerResult
from src.workers.audit import AuditWorker
from src.workers.base import BaseWorker
from src.workers.system import SystemWorker


class OrchestratorEngine:
    """Orchestrator å¼•æ“

    å®ç° ReAct (Reason-Act) å¾ªç¯ï¼š
    1. Reason: LLM ç”Ÿæˆä¸‹ä¸€æ­¥æŒ‡ä»¤
    2. Safety Check: æ£€æŸ¥å®‰å…¨çº§åˆ«
    3. Act: æ‰§è¡Œ Worker
    4. åˆ¤æ–­æ˜¯å¦å®Œæˆ
    """

    def __init__(
        self,
        config: OpsAIConfig,
        confirmation_callback: Optional[Callable[[Instruction, RiskLevel], bool]] = None,
        dry_run: bool = False,
        progress_callback: Optional[Callable[[str, str], None]] = None,
    ) -> None:
        """åˆå§‹åŒ–å¼•æ“

        Args:
            config: é…ç½®å¯¹è±¡
            confirmation_callback: ç¡®è®¤å›è°ƒå‡½æ•°ï¼Œç”¨äºé«˜å±æ“ä½œç¡®è®¤
            dry_run: æ˜¯å¦å¯ç”¨ dry-run æ¨¡å¼
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°ï¼Œæ¥æ”¶ (step_name, message) ç”¨äºå®æ—¶æ˜¾ç¤ºè¿›åº¦
        """
        self._config = config
        self._llm_client = LLMClient(config.llm)
        self._prompt_builder = PromptBuilder()
        self._context = EnvironmentContext()
        self._confirmation_callback = confirmation_callback
        self._dry_run = dry_run or config.safety.dry_run_by_default
        self._progress_callback = progress_callback

        # åˆå§‹åŒ– Workers
        self._workers: dict[str, BaseWorker] = {
            "system": SystemWorker(),
            "audit": AuditWorker(),
        }

        # æ³¨å†Œ ChatWorker
        try:
            from src.workers.chat import ChatWorker
            self._workers["chat"] = ChatWorker()
        except ImportError:
            pass

        # æ³¨å†Œ ShellWorker
        try:
            from src.workers.shell import ShellWorker
            self._workers["shell"] = ShellWorker()
        except ImportError:
            pass

        # å°è¯•å¯¼å…¥å¹¶æ³¨å†Œ ContainerWorker
        try:
            from src.workers.container import ContainerWorker
            self._workers["container"] = ContainerWorker()
        except ImportError:
            pass

    def get_worker(self, name: str) -> Optional[BaseWorker]:
        """è·å– Worker

        Args:
            name: Worker åç§°

        Returns:
            Worker å®ä¾‹ï¼Œä¸å­˜åœ¨è¿”å› None
        """
        return self._workers.get(name)

    async def execute_instruction(self, instruction: Instruction) -> WorkerResult:
        """æ‰§è¡ŒæŒ‡ä»¤

        Args:
            instruction: å¾…æ‰§è¡Œçš„æŒ‡ä»¤

        Returns:
            æ‰§è¡Œç»“æœ
        """
        worker = self.get_worker(instruction.worker)
        if worker is None:
            return WorkerResult(
                success=False,
                message=f"Unknown worker: {instruction.worker}",
            )

        # å¦‚æœå…¨å±€å¯ç”¨äº† dry_runï¼Œåˆ™æ³¨å…¥åˆ°å‚æ•°ä¸­
        args = instruction.args.copy()
        if self._dry_run or instruction.dry_run:
            args["dry_run"] = True

        return await worker.execute(instruction.action, args)

    async def react_loop(
        self,
        user_input: str,
        max_iterations: int = 5,
    ) -> str:
        """æ‰§è¡Œ ReAct å¾ªç¯

        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œé˜²æ­¢æ­»å¾ªç¯

        Returns:
            æœ€ç»ˆç»“æœæ¶ˆæ¯
        """
        conversation_history: list[ConversationEntry] = []

        for iteration in range(max_iterations):
            # 1. Reason: LLM ç”Ÿæˆä¸‹ä¸€æ­¥æŒ‡ä»¤
            if self._progress_callback:
                self._progress_callback("reasoning", "ğŸ¤” Analyzing your request...")

            system_prompt = self._prompt_builder.build_system_prompt(self._context)
            user_prompt = self._prompt_builder.build_user_prompt(
                user_input, history=conversation_history
            )

            llm_response = await self._llm_client.generate(system_prompt, user_prompt)
            parsed = self._llm_client.parse_json_response(llm_response)

            if parsed is None:
                return f"Error: Failed to parse LLM response: {llm_response}"

            # æ„å»ºæŒ‡ä»¤
            instruction = Instruction(
                worker=str(parsed.get("worker", "")),
                action=str(parsed.get("action", "")),
                args=parsed.get("args", {}),  # type: ignore[arg-type]
                risk_level=parsed.get("risk_level", "safe"),  # type: ignore[arg-type]
            )

            # æ˜¾ç¤ºç”Ÿæˆçš„æŒ‡ä»¤
            if self._progress_callback:
                self._progress_callback(
                    "instruction",
                    f"ğŸ“‹ Instruction: {instruction.worker}.{instruction.action}(args={instruction.args})"
                )

            # 2. Safety Check
            risk = check_safety(instruction)
            if self._progress_callback:
                risk_emoji = {"safe": "âœ…", "medium": "âš ï¸", "high": "ğŸš¨"}.get(risk, "â“")
                self._progress_callback("safety", f"{risk_emoji} Risk level: {risk}")
            if risk in ["medium", "high"]:
                if self._confirmation_callback:
                    confirmed = self._confirmation_callback(instruction, risk)
                    if not confirmed:
                        # è®°å½•æ‹’ç»
                        await self._log_operation(
                            user_input, instruction, risk, confirmed=False, exit_code=-1, output="Rejected by user"
                        )
                        return "Operation cancelled by user"
                else:
                    # CLI æ¨¡å¼æ— ç¡®è®¤å›è°ƒï¼Œè‡ªåŠ¨æ‹’ç»
                    return f"Error: {risk.upper()}-risk operation requires TUI mode for confirmation"

            # 3. Act: æ‰§è¡Œ Worker
            if self._progress_callback:
                self._progress_callback("executing", f"âš™ï¸  Executing {instruction.worker}.{instruction.action}...")

            result = await self.execute_instruction(instruction)

            if self._progress_callback:
                status_emoji = "âœ…" if result.success else "âŒ"
                self._progress_callback("result", f"{status_emoji} {result.message}")

            # 4. è®°å½•åˆ°å®¡è®¡æ—¥å¿—
            await self._log_operation(
                user_input, instruction, risk, confirmed=True,
                exit_code=0 if result.success else 1,
                output=result.message,
            )

            # 5. è®°å½•å†å²
            conversation_history.append(
                ConversationEntry(instruction=instruction, result=result)
            )

            # 6. åˆ¤æ–­æ˜¯å¦å®Œæˆ
            if result.task_completed:
                return result.message

        return "Task incomplete: reached maximum iterations"

    async def _log_operation(
        self,
        user_input: str,
        instruction: Instruction,
        risk: RiskLevel,
        confirmed: bool,
        exit_code: int,
        output: str,
    ) -> None:
        """è®°å½•æ“ä½œåˆ°å®¡è®¡æ—¥å¿—"""
        audit_worker = self._workers.get("audit")
        if audit_worker:
            await audit_worker.execute(
                "log_operation",
                {
                    "input": user_input,
                    "worker": instruction.worker,
                    "action": instruction.action,
                    "risk": risk,
                    "confirmed": "yes" if confirmed else "no",
                    "exit_code": exit_code,
                    "output": output,
                },
            )
